def forward(self, primals, tangents):
    primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, tangents_1, tangents_2, = fx_pytree.tree_flatten_spec([primals, tangents], self._in_spec)
    embedding = torch.ops.aten.embedding.default(primals_2, primals_1);  primals_2 = None
    iota = torch.ops.prims.iota.default(1024, start = 0, step = 1, dtype = torch.int64, device = device(type='cuda', index=0), requires_grad = False)
    unsqueeze = torch.ops.aten.unsqueeze.default(iota, 0);  iota = None
    full = torch.ops.aten.full.default([2048, 2048], -3.3895313892515355e+38, dtype = torch.bfloat16, device = device(type='cuda', index=0), pin_memory = False)
    iota_1 = torch.ops.prims.iota.default(2048, start = 0, step = 1, dtype = torch.int64, device = device(type='cuda', index=0), requires_grad = False)
    unsqueeze_1 = torch.ops.aten.unsqueeze.default(iota_1, -2);  iota_1 = None
    iota_2 = torch.ops.prims.iota.default(2048, start = 0, step = 1, dtype = torch.int64, device = device(type='cuda', index=0), requires_grad = False)
    unsqueeze_2 = torch.ops.aten.unsqueeze.default(iota_2, -1);  iota_2 = None
    sub = torch.ops.aten.sub.Tensor(unsqueeze_1, unsqueeze_2);  unsqueeze_1 = unsqueeze_2 = None
    ge = torch.ops.aten.ge.Scalar(sub, 1);  sub = None
    scalar_tensor = torch.ops.aten.scalar_tensor.default(0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0))
    where = torch.ops.aten.where.self(ge, full, scalar_tensor);  ge = full = scalar_tensor = None
    iota_3 = torch.ops.prims.iota.default(2048, start = 0, step = 1, dtype = torch.int64, device = device(type='cuda', index=0), requires_grad = False)
    iota_4 = torch.ops.prims.iota.default(2048, start = 0, step = 1, dtype = torch.int64, device = device(type='cuda', index=0), requires_grad = False)
    view = torch.ops.aten.view.default(iota_4, [-1, 1]);  iota_4 = None
    gt = torch.ops.aten.gt.Tensor(iota_3, view);  iota_3 = view = None
    mul = torch.ops.aten.mul.Tensor(where, gt);  where = gt = None
    unsqueeze_5 = torch.ops.aten.unsqueeze.default(mul, 0);  mul = None
    unsqueeze_6 = torch.ops.aten.unsqueeze.default(unsqueeze_5, 1);  unsqueeze_5 = None
    slice_3 = torch.ops.aten.slice.Tensor(unsqueeze_6, 2, 0, 9223372036854775807);  unsqueeze_6 = None
    slice_4 = torch.ops.aten.slice.Tensor(slice_3, 3, 0, 9223372036854775807);  slice_3 = None
    expand_1 = torch.ops.aten.expand.default(slice_4, [1, 1, -1, -1]);  slice_4 = None
    clone = torch.ops.aten.clone.default(expand_1);  expand_1 = None
    slice_5 = torch.ops.aten.slice.Tensor(clone, 0, 0, 9223372036854775807)
    slice_6 = torch.ops.aten.slice.Tensor(slice_5, 1, 0, 9223372036854775807);  slice_5 = None
    slice_7 = torch.ops.aten.slice.Tensor(slice_6, 2, 0, 9223372036854775807);  slice_6 = None
    slice_8 = torch.ops.aten.slice.Tensor(primals_3, 0, 0, 9223372036854775807);  primals_3 = None
    unsqueeze_7 = torch.ops.aten.unsqueeze.default(slice_8, 1);  slice_8 = None
    unsqueeze_8 = torch.ops.aten.unsqueeze.default(unsqueeze_7, 2);  unsqueeze_7 = None
    slice_9 = torch.ops.aten.slice.Tensor(unsqueeze_8, 3, 0, 9223372036854775807);  unsqueeze_8 = None
    add = torch.ops.aten.add.Tensor(slice_7, slice_9);  slice_7 = slice_9 = None
    eq = torch.ops.aten.eq.Scalar(add, 0);  add = None
    slice_10 = torch.ops.aten.slice.Tensor(clone, 0, 0, 9223372036854775807)
    slice_11 = torch.ops.aten.slice.Tensor(slice_10, 1, 0, 9223372036854775807);  slice_10 = None
    slice_12 = torch.ops.aten.slice.Tensor(slice_11, 2, 0, 9223372036854775807);  slice_11 = None
    scalar_tensor_1 = torch.ops.aten.scalar_tensor.default(-3.3895313892515355e+38, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0))
    where_1 = torch.ops.aten.where.self(eq, scalar_tensor_1, slice_12);  eq = scalar_tensor_1 = slice_12 = None
    slice_13 = torch.ops.aten.slice.Tensor(clone, 0, 0, 9223372036854775807)
    slice_14 = torch.ops.aten.slice.Tensor(slice_13, 1, 0, 9223372036854775807);  slice_13 = None
    slice_15 = torch.ops.aten.slice.Tensor(slice_14, 2, 0, 9223372036854775807);  slice_14 = None
    copy = torch.ops.aten.copy.default(slice_15, where_1);  slice_15 = where_1 = None
    slice_16 = torch.ops.aten.slice.Tensor(clone, 0, 0, 9223372036854775807)
    slice_17 = torch.ops.aten.slice.Tensor(slice_16, 1, 0, 9223372036854775807)
    slice_scatter = torch.ops.aten.slice_scatter.default(slice_17, copy, 2, 0, 9223372036854775807);  slice_17 = copy = None
    slice_scatter_1 = torch.ops.aten.slice_scatter.default(slice_16, slice_scatter, 1, 0, 9223372036854775807);  slice_16 = slice_scatter = None
    slice_scatter_2 = torch.ops.aten.slice_scatter.default(clone, slice_scatter_1, 0, 0, 9223372036854775807);  clone = slice_scatter_1 = None
    eq_1 = torch.ops.aten.eq.Scalar(slice_scatter_2, -3.3895313892515355e+38)
    logical_not = torch.ops.aten.logical_not.default(eq_1);  eq_1 = None
    any_1 = torch.ops.aten.any.dim(logical_not, -1, True);  logical_not = None
    logical_not_1 = torch.ops.aten.logical_not.default(any_1);  any_1 = None
    bitwise_not = torch.ops.aten.bitwise_not.default(logical_not_1);  logical_not_1 = None
    mul_1 = torch.ops.aten.mul.Tensor(slice_scatter_2, bitwise_not);  slice_scatter_2 = bitwise_not = None
    unsqueeze_9 = torch.ops.aten.unsqueeze.default(primals_4, 0);  primals_4 = None
    slice_21 = torch.ops.aten.slice.Tensor(unsqueeze_9, 1, 0, 9223372036854775807);  unsqueeze_9 = None
    unsqueeze_10 = torch.ops.aten.unsqueeze.default(slice_21, 2);  slice_21 = None
    convert_element_type = torch.ops.prims.convert_element_type.default(unsqueeze_10, torch.float32);  unsqueeze_10 = None
    expand_2 = torch.ops.aten.expand.default(convert_element_type, [1, -1, 1]);  convert_element_type = None
    slice_22 = torch.ops.aten.slice.Tensor(unsqueeze, 0, 0, 9223372036854775807);  unsqueeze = None
    unsqueeze_11 = torch.ops.aten.unsqueeze.default(slice_22, 1);  slice_22 = None
    slice_23 = torch.ops.aten.slice.Tensor(unsqueeze_11, 2, 0, 9223372036854775807);  unsqueeze_11 = None
    convert_element_type_1 = torch.ops.prims.convert_element_type.default(slice_23, torch.float32);  slice_23 = None
    expand_3 = torch.ops.aten.expand.default(expand_2, [1, 64, 1]);  expand_2 = None
    view_1 = torch.ops.aten.view.default(expand_3, [1, 64, 1]);  expand_3 = None
    expand_4 = torch.ops.aten.expand.default(convert_element_type_1, [1, 1, 1024]);  convert_element_type_1 = None
    view_2 = torch.ops.aten.view.default(expand_4, [1, 1, 1024]);  expand_4 = None
    bmm = torch.ops.aten.bmm.default(view_1, view_2);  view_1 = view_2 = None
    view_3 = torch.ops.aten.view.default(bmm, [1, 64, 1024]);  bmm = None
    permute = torch.ops.aten.permute.default(view_3, [0, 2, 1]);  view_3 = None
    unsqueeze_12 = torch.ops.aten.unsqueeze.default(permute, 2);  permute = None
    expand_5 = torch.ops.aten.expand.default(unsqueeze_12, [1, 1024, 2, 64]);  unsqueeze_12 = None
    clone_1 = torch.ops.aten.clone.default(expand_5, memory_format = torch.contiguous_format);  expand_5 = None
    view_4 = torch.ops.aten.view.default(clone_1, [1, 1024, 128]);  clone_1 = None
    clone_2 = torch.ops.aten.clone.default(view_4);  view_4 = None
    cos = torch.ops.aten.cos.default(clone_2)
    sin = torch.ops.aten.sin.default(clone_2);  clone_2 = None
    mul_2 = torch.ops.aten.mul.Tensor(cos, 1.0);  cos = None
    mul_3 = torch.ops.aten.mul.Tensor(sin, 1.0);  sin = None
    convert_element_type_2 = torch.ops.prims.convert_element_type.default(mul_2, torch.bfloat16);  mul_2 = None
    convert_element_type_3 = torch.ops.prims.convert_element_type.default(mul_3, torch.bfloat16);  mul_3 = None
    convert_element_type_4 = torch.ops.prims.convert_element_type.default(embedding, torch.float32)
    pow_1 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_4, 2)
    mean = torch.ops.aten.mean.dim(pow_1, [-1], True);  pow_1 = None
    add_1 = torch.ops.aten.add.Tensor(mean, 1e-05);  mean = None
    rsqrt = torch.ops.aten.rsqrt.default(add_1);  add_1 = None
    alias = torch.ops.aten.alias.default(rsqrt)
    alias_1 = torch.ops.aten.alias.default(alias);  alias = None
    mul_4 = torch.ops.aten.mul.Tensor(convert_element_type_4, rsqrt)
    convert_element_type_5 = torch.ops.prims.convert_element_type.default(mul_4, torch.bfloat16);  mul_4 = None
    mul_5 = torch.ops.aten.mul.Tensor(primals_5, convert_element_type_5)
    permute_1 = torch.ops.aten.permute.default(primals_6, [1, 0]);  primals_6 = None
    view_5 = torch.ops.aten.view.default(mul_5, [1024, 4096])
    mm = torch.ops.aten.mm.default(view_5, permute_1)
    view_6 = torch.ops.aten.view.default(mm, [1, 1024, 4096]);  mm = None
    view_7 = torch.ops.aten.view.default(view_6, [1, 1024, -1, 128]);  view_6 = None
    permute_2 = torch.ops.aten.permute.default(view_7, [0, 2, 1, 3]);  view_7 = None
    permute_3 = torch.ops.aten.permute.default(primals_7, [1, 0]);  primals_7 = None
    view_8 = torch.ops.aten.view.default(mul_5, [1024, 4096])
    mm_1 = torch.ops.aten.mm.default(view_8, permute_3)
    view_9 = torch.ops.aten.view.default(mm_1, [1, 1024, 4096]);  mm_1 = None
    view_10 = torch.ops.aten.view.default(view_9, [1, 1024, -1, 128]);  view_9 = None
    permute_4 = torch.ops.aten.permute.default(view_10, [0, 2, 1, 3]);  view_10 = None
    permute_5 = torch.ops.aten.permute.default(primals_8, [1, 0]);  primals_8 = None
    view_11 = torch.ops.aten.view.default(mul_5, [1024, 4096]);  mul_5 = None
    mm_2 = torch.ops.aten.mm.default(view_11, permute_5)
    view_12 = torch.ops.aten.view.default(mm_2, [1, 1024, 4096]);  mm_2 = None
    view_13 = torch.ops.aten.view.default(view_12, [1, 1024, -1, 128]);  view_12 = None
    permute_6 = torch.ops.aten.permute.default(view_13, [0, 2, 1, 3]);  view_13 = None
    unsqueeze_13 = torch.ops.aten.unsqueeze.default(convert_element_type_2, 1);  convert_element_type_2 = None
    unsqueeze_14 = torch.ops.aten.unsqueeze.default(convert_element_type_3, 1);  convert_element_type_3 = None
    mul_6 = torch.ops.aten.mul.Tensor(permute_2, unsqueeze_13)
    slice_24 = torch.ops.aten.slice.Tensor(permute_2, 3, 0, 64)
    slice_25 = torch.ops.aten.slice.Tensor(permute_2, 3, 64, 9223372036854775807);  permute_2 = None
    neg = torch.ops.aten.neg.default(slice_25);  slice_25 = None
    cat = torch.ops.aten.cat.default([neg, slice_24], -1);  neg = slice_24 = None
    mul_7 = torch.ops.aten.mul.Tensor(cat, unsqueeze_14);  cat = None
    add_2 = torch.ops.aten.add.Tensor(mul_6, mul_7);  mul_6 = mul_7 = None
    mul_8 = torch.ops.aten.mul.Tensor(permute_4, unsqueeze_13)
    slice_26 = torch.ops.aten.slice.Tensor(permute_4, 3, 0, 64)
    slice_27 = torch.ops.aten.slice.Tensor(permute_4, 3, 64, 9223372036854775807);  permute_4 = None
    neg_1 = torch.ops.aten.neg.default(slice_27);  slice_27 = None
    cat_1 = torch.ops.aten.cat.default([neg_1, slice_26], -1);  neg_1 = slice_26 = None
    mul_9 = torch.ops.aten.mul.Tensor(cat_1, unsqueeze_14);  cat_1 = None
    add_3 = torch.ops.aten.add.Tensor(mul_8, mul_9);  mul_8 = mul_9 = None
    slice_28 = torch.ops.aten.slice.Tensor(mul_1, 0, 0, 9223372036854775807);  mul_1 = None
    slice_29 = torch.ops.aten.slice.Tensor(slice_28, 1, 0, 9223372036854775807);  slice_28 = None
    slice_30 = torch.ops.aten.slice.Tensor(slice_29, 2, 0, 9223372036854775807);  slice_29 = None
    clone_3 = torch.ops.aten.clone.default(add_2, memory_format = torch.contiguous_format);  add_2 = None
    all_to_all_qkv = torch.ops.ulysses.all_to_all_qkv.default(clone_3, 1, 2048, 32, 128, 2);  clone_3 = None
    clone_4 = torch.ops.aten.clone.default(add_3, memory_format = torch.contiguous_format);  add_3 = None
    all_to_all_qkv_1 = torch.ops.ulysses.all_to_all_qkv.default(clone_4, 1, 2048, 32, 128, 2);  clone_4 = None
    clone_5 = torch.ops.aten.clone.default(permute_6, memory_format = torch.contiguous_format);  permute_6 = None
    all_to_all_qkv_2 = torch.ops.ulysses.all_to_all_qkv.default(clone_5, 1, 2048, 32, 128, 2);  clone_5 = None
    expand_6 = torch.ops.aten.expand.default(slice_30, [1, 16, 2048, 2048]);  slice_30 = None
    _scaled_dot_product_efficient_attention = torch.ops.aten._scaled_dot_product_efficient_attention.default(all_to_all_qkv, all_to_all_qkv_1, all_to_all_qkv_2, expand_6, True, scale = 0.08838834764831845)
    getitem = _scaled_dot_product_efficient_attention[0]
    getitem_1 = _scaled_dot_product_efficient_attention[1]
    getitem_2 = _scaled_dot_product_efficient_attention[2]
    getitem_3 = _scaled_dot_product_efficient_attention[3];  _scaled_dot_product_efficient_attention = None
    alias_2 = torch.ops.aten.alias.default(getitem)
    alias_3 = torch.ops.aten.alias.default(alias_2);  alias_2 = None
    all_to_all_out = torch.ops.ulysses.all_to_all_out.default(getitem, 1, 2048, 32, 128, 2);  getitem = None
    permute_7 = torch.ops.aten.permute.default(all_to_all_out, [0, 2, 1, 3]);  all_to_all_out = None
    clone_6 = torch.ops.aten.clone.default(permute_7, memory_format = torch.contiguous_format);  permute_7 = None
    view_14 = torch.ops.aten.view.default(clone_6, [1, 1024, -1]);  clone_6 = None
    permute_8 = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None
    view_15 = torch.ops.aten.view.default(view_14, [1024, 4096]);  view_14 = None
    mm_3 = torch.ops.aten.mm.default(view_15, permute_8)
    view_16 = torch.ops.aten.view.default(mm_3, [1, 1024, 4096]);  mm_3 = None
    add_4 = torch.ops.aten.add.Tensor(embedding, view_16);  embedding = view_16 = None
    convert_element_type_14 = torch.ops.prims.convert_element_type.default(add_4, torch.float32)
    pow_2 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_14, 2)
    mean_1 = torch.ops.aten.mean.dim(pow_2, [-1], True);  pow_2 = None
    add_5 = torch.ops.aten.add.Tensor(mean_1, 1e-05);  mean_1 = None
    rsqrt_1 = torch.ops.aten.rsqrt.default(add_5);  add_5 = None
    alias_4 = torch.ops.aten.alias.default(rsqrt_1)
    alias_5 = torch.ops.aten.alias.default(alias_4);  alias_4 = None
    mul_10 = torch.ops.aten.mul.Tensor(convert_element_type_14, rsqrt_1)
    convert_element_type_15 = torch.ops.prims.convert_element_type.default(mul_10, torch.bfloat16);  mul_10 = None
    mul_11 = torch.ops.aten.mul.Tensor(primals_10, convert_element_type_15)
    permute_9 = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None
    view_17 = torch.ops.aten.view.default(mul_11, [1024, 4096])
    mm_4 = torch.ops.aten.mm.default(view_17, permute_9)
    view_18 = torch.ops.aten.view.default(mm_4, [1, 1024, 11008]);  mm_4 = None
    convert_element_type_18 = torch.ops.prims.convert_element_type.default(view_18, torch.float32)
    sigmoid = torch.ops.aten.sigmoid.default(convert_element_type_18)
    mul_12 = torch.ops.aten.mul.Tensor(convert_element_type_18, sigmoid);  convert_element_type_18 = sigmoid = None
    convert_element_type_19 = torch.ops.prims.convert_element_type.default(mul_12, torch.bfloat16);  mul_12 = None
    permute_10 = torch.ops.aten.permute.default(primals_12, [1, 0]);  primals_12 = None
    view_19 = torch.ops.aten.view.default(mul_11, [1024, 4096]);  mul_11 = None
    mm_5 = torch.ops.aten.mm.default(view_19, permute_10)
    view_20 = torch.ops.aten.view.default(mm_5, [1, 1024, 11008]);  mm_5 = None
    mul_13 = torch.ops.aten.mul.Tensor(convert_element_type_19, view_20)
    permute_11 = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None
    view_21 = torch.ops.aten.view.default(mul_13, [1024, 11008]);  mul_13 = None
    mm_6 = torch.ops.aten.mm.default(view_21, permute_11)
    view_22 = torch.ops.aten.view.default(mm_6, [1, 1024, 4096]);  mm_6 = None
    add_6 = torch.ops.aten.add.Tensor(add_4, view_22);  add_4 = view_22 = None
    convert_element_type_24 = torch.ops.prims.convert_element_type.default(add_6, torch.float32);  add_6 = None
    pow_3 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_24, 2)
    mean_2 = torch.ops.aten.mean.dim(pow_3, [-1], True);  pow_3 = None
    add_7 = torch.ops.aten.add.Tensor(mean_2, 1e-05);  mean_2 = None
    rsqrt_2 = torch.ops.aten.rsqrt.default(add_7);  add_7 = None
    alias_6 = torch.ops.aten.alias.default(rsqrt_2)
    alias_7 = torch.ops.aten.alias.default(alias_6);  alias_6 = None
    mul_14 = torch.ops.aten.mul.Tensor(convert_element_type_24, rsqrt_2)
    convert_element_type_25 = torch.ops.prims.convert_element_type.default(mul_14, torch.bfloat16);  mul_14 = None
    mul_15 = torch.ops.aten.mul.Tensor(primals_14, convert_element_type_25)
    slice_31 = torch.ops.aten.slice.Tensor(mul_15, 0, 0, 9223372036854775807);  mul_15 = None
    slice_32 = torch.ops.aten.slice.Tensor(slice_31, 1, 0, 9223372036854775807);  slice_31 = None
    slice_33 = torch.ops.aten.slice.Tensor(slice_32, 2, 0, 9223372036854775807);  slice_32 = None
    permute_12 = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None
    view_23 = torch.ops.aten.view.default(slice_33, [1024, 4096]);  slice_33 = None
    mm_7 = torch.ops.aten.mm.default(view_23, permute_12)
    view_24 = torch.ops.aten.view.default(mm_7, [1, 1024, 32000]);  mm_7 = None
    convert_element_type_28 = torch.ops.prims.convert_element_type.default(view_24, torch.float32)
    constant_pad_nd = torch.ops.aten.constant_pad_nd.default(primals_16, [0, 1], -100.0);  primals_16 = None
    slice_34 = torch.ops.aten.slice.Tensor(constant_pad_nd, 1, 1, 9223372036854775807);  constant_pad_nd = None
    view_25 = torch.ops.aten.view.default(convert_element_type_28, [-1, 32000]);  convert_element_type_28 = None
    view_26 = torch.ops.aten.view.default(slice_34, [-1]);  slice_34 = None
    amax = torch.ops.aten.amax.default(view_25, [1], True)
    sub_1 = torch.ops.aten.sub.Tensor(view_25, amax);  view_25 = amax = None
    exp = torch.ops.aten.exp.default(sub_1)
    sum_1 = torch.ops.aten.sum.dim_IntList(exp, [1], True);  exp = None
    log = torch.ops.aten.log.default(sum_1);  sum_1 = None
    sub_2 = torch.ops.aten.sub.Tensor(sub_1, log);  sub_1 = log = None
    alias_8 = torch.ops.aten.alias.default(sub_2)
    alias_9 = torch.ops.aten.alias.default(alias_8);  alias_8 = None
    ne = torch.ops.aten.ne.Scalar(view_26, -100)
    scalar_tensor_2 = torch.ops.aten.scalar_tensor.default(0, dtype = torch.int64, layout = torch.strided, device = device(type='cuda', index=0))
    where_2 = torch.ops.aten.where.self(ne, view_26, scalar_tensor_2);  ne = scalar_tensor_2 = None
    unsqueeze_15 = torch.ops.aten.unsqueeze.default(where_2, 1);  where_2 = None
    gather = torch.ops.aten.gather.default(sub_2, 1, unsqueeze_15);  sub_2 = unsqueeze_15 = None
    squeeze = torch.ops.aten.squeeze.dim(gather, 1);  gather = None
    neg_2 = torch.ops.aten.neg.default(squeeze);  squeeze = None
    ne_1 = torch.ops.aten.ne.Scalar(view_26, -100)
    scalar_tensor_3 = torch.ops.aten.scalar_tensor.default(0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
    where_3 = torch.ops.aten.where.self(ne_1, neg_2, scalar_tensor_3);  ne_1 = neg_2 = scalar_tensor_3 = None
    ne_2 = torch.ops.aten.ne.Scalar(view_26, -100)
    sum_2 = torch.ops.aten.sum.default(ne_2);  ne_2 = None
    convert_element_type_29 = torch.ops.prims.convert_element_type.default(sum_2, torch.float32);  sum_2 = None
    sum_3 = torch.ops.aten.sum.default(where_3);  where_3 = None
    div = torch.ops.aten.div.Tensor(sum_3, convert_element_type_29);  sum_3 = None
    div_1 = torch.ops.aten.div.Tensor(tangents_1, convert_element_type_29);  tangents_1 = convert_element_type_29 = None
    unsqueeze_16 = torch.ops.aten.unsqueeze.default(view_26, 1);  view_26 = None
    ne_3 = torch.ops.aten.ne.Scalar(unsqueeze_16, -100)
    scalar_tensor_4 = torch.ops.aten.scalar_tensor.default(0, dtype = torch.int64, layout = torch.strided, device = device(type='cuda', index=0))
    where_4 = torch.ops.aten.where.self(ne_3, unsqueeze_16, scalar_tensor_4);  ne_3 = scalar_tensor_4 = None
    full_1 = torch.ops.aten.full.default([1024, 32000], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
    scatter = torch.ops.aten.scatter.value(full_1, 1, where_4, -1.0);  full_1 = where_4 = None
    ne_4 = torch.ops.aten.ne.Scalar(unsqueeze_16, -100);  unsqueeze_16 = None
    scalar_tensor_5 = torch.ops.aten.scalar_tensor.default(0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
    where_5 = torch.ops.aten.where.self(ne_4, div_1, scalar_tensor_5);  ne_4 = div_1 = scalar_tensor_5 = None
    mul_16 = torch.ops.aten.mul.Tensor(scatter, where_5);  scatter = where_5 = None
    alias_10 = torch.ops.aten.alias.default(alias_9);  alias_9 = None
    alias_11 = torch.ops.aten.alias.default(alias_10);  alias_10 = None
    exp_1 = torch.ops.aten.exp.default(alias_11);  alias_11 = None
    sum_4 = torch.ops.aten.sum.dim_IntList(mul_16, [1], True)
    mul_17 = torch.ops.aten.mul.Tensor(exp_1, sum_4);  exp_1 = sum_4 = None
    sub_3 = torch.ops.aten.sub.Tensor(mul_16, mul_17);  mul_16 = mul_17 = None
    view_27 = torch.ops.aten.view.default(sub_3, [1, 1024, 32000]);  sub_3 = None
    convert_element_type_30 = torch.ops.prims.convert_element_type.default(view_27, torch.bfloat16);  view_27 = None
    add_8 = torch.ops.aten.add.Tensor(tangents_2, convert_element_type_30);  tangents_2 = convert_element_type_30 = None
    view_28 = torch.ops.aten.view.default(add_8, [1024, 32000]);  add_8 = None
    permute_13 = torch.ops.aten.permute.default(view_28, [1, 0])
    mm_8 = torch.ops.aten.mm.default(permute_13, view_23);  permute_13 = view_23 = None
    permute_14 = torch.ops.aten.permute.default(mm_8, [1, 0]);  mm_8 = None
    permute_15 = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None
    mm_9 = torch.ops.aten.mm.default(view_28, permute_15);  view_28 = permute_15 = None
    view_29 = torch.ops.aten.view.default(mm_9, [1, 1024, 4096]);  mm_9 = None
    permute_16 = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None
    full_2 = torch.ops.aten.full.default([1, 1024, 4096], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
    slice_scatter_3 = torch.ops.aten.slice_scatter.default(full_2, view_29, 2, 0, 9223372036854775807);  full_2 = view_29 = None
    full_3 = torch.ops.aten.full.default([1, 1024, 4096], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
    slice_scatter_4 = torch.ops.aten.slice_scatter.default(full_3, slice_scatter_3, 1, 0, 9223372036854775807);  full_3 = slice_scatter_3 = None
    full_4 = torch.ops.aten.full.default([1, 1024, 4096], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
    slice_scatter_5 = torch.ops.aten.slice_scatter.default(full_4, slice_scatter_4, 0, 0, 9223372036854775807);  full_4 = slice_scatter_4 = None
    mul_18 = torch.ops.aten.mul.Tensor(slice_scatter_5, primals_14);  primals_14 = None
    mul_19 = torch.ops.aten.mul.Tensor(slice_scatter_5, convert_element_type_25);  slice_scatter_5 = convert_element_type_25 = None
    sum_5 = torch.ops.aten.sum.dim_IntList(mul_19, [0, 1], True);  mul_19 = None
    view_30 = torch.ops.aten.view.default(sum_5, [4096]);  sum_5 = None
    convert_element_type_35 = torch.ops.prims.convert_element_type.default(mul_18, torch.float32);  mul_18 = None
    mul_20 = torch.ops.aten.mul.Tensor(convert_element_type_35, convert_element_type_24)
    mul_21 = torch.ops.aten.mul.Tensor(convert_element_type_35, rsqrt_2);  convert_element_type_35 = rsqrt_2 = None
    sum_6 = torch.ops.aten.sum.dim_IntList(mul_20, [2], True);  mul_20 = None
    alias_12 = torch.ops.aten.alias.default(alias_7);  alias_7 = None
    alias_13 = torch.ops.aten.alias.default(alias_12);  alias_12 = None
    pow_4 = torch.ops.aten.pow.Tensor_Scalar(alias_13, 3);  alias_13 = None
    mul_22 = torch.ops.aten.mul.Scalar(sum_6, -0.5);  sum_6 = None
    mul_23 = torch.ops.aten.mul.Tensor(mul_22, pow_4);  mul_22 = pow_4 = None
    expand_7 = torch.ops.aten.expand.default(mul_23, [1, 1024, 4096]);  mul_23 = None
    div_2 = torch.ops.aten.div.Scalar(expand_7, 4096);  expand_7 = None
    pow_5 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_24, 1.0);  convert_element_type_24 = None
    mul_24 = torch.ops.aten.mul.Scalar(pow_5, 2.0);  pow_5 = None
    mul_25 = torch.ops.aten.mul.Tensor(div_2, mul_24);  div_2 = mul_24 = None
    add_9 = torch.ops.aten.add.Tensor(mul_21, mul_25);  mul_21 = mul_25 = None
    convert_element_type_36 = torch.ops.prims.convert_element_type.default(add_9, torch.bfloat16);  add_9 = None
    view_31 = torch.ops.aten.view.default(convert_element_type_36, [1024, 4096])
    permute_17 = torch.ops.aten.permute.default(view_31, [1, 0])
    mm_10 = torch.ops.aten.mm.default(permute_17, view_21);  permute_17 = view_21 = None
    permute_18 = torch.ops.aten.permute.default(mm_10, [1, 0]);  mm_10 = None
    permute_19 = torch.ops.aten.permute.default(permute_11, [1, 0]);  permute_11 = None
    mm_11 = torch.ops.aten.mm.default(view_31, permute_19);  view_31 = permute_19 = None
    view_32 = torch.ops.aten.view.default(mm_11, [1, 1024, 11008]);  mm_11 = None
    permute_20 = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None
    mul_26 = torch.ops.aten.mul.Tensor(view_32, convert_element_type_19);  convert_element_type_19 = None
    mul_27 = torch.ops.aten.mul.Tensor(view_32, view_20);  view_32 = view_20 = None
    view_33 = torch.ops.aten.view.default(mul_26, [1024, 11008]);  mul_26 = None
    permute_21 = torch.ops.aten.permute.default(view_33, [1, 0])
    mm_12 = torch.ops.aten.mm.default(permute_21, view_19);  permute_21 = view_19 = None
    permute_22 = torch.ops.aten.permute.default(mm_12, [1, 0]);  mm_12 = None
    permute_23 = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None
    mm_13 = torch.ops.aten.mm.default(view_33, permute_23);  view_33 = permute_23 = None
    view_34 = torch.ops.aten.view.default(mm_13, [1, 1024, 4096]);  mm_13 = None
    permute_24 = torch.ops.aten.permute.default(permute_22, [1, 0]);  permute_22 = None
    sigmoid_1 = torch.ops.aten.sigmoid.default(view_18)
    full_5 = torch.ops.aten.full.default([1, 1024, 11008], 1, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
    sub_4 = torch.ops.aten.sub.Tensor(full_5, sigmoid_1);  full_5 = None
    mul_28 = torch.ops.aten.mul.Tensor(view_18, sub_4);  view_18 = sub_4 = None
    add_10 = torch.ops.aten.add.Scalar(mul_28, 1);  mul_28 = None
    mul_29 = torch.ops.aten.mul.Tensor(sigmoid_1, add_10);  sigmoid_1 = add_10 = None
    mul_30 = torch.ops.aten.mul.Tensor(mul_27, mul_29);  mul_27 = mul_29 = None
    view_35 = torch.ops.aten.view.default(mul_30, [1024, 11008]);  mul_30 = None
    permute_26 = torch.ops.aten.permute.default(view_35, [1, 0])
    mm_14 = torch.ops.aten.mm.default(permute_26, view_17);  permute_26 = view_17 = None
    permute_27 = torch.ops.aten.permute.default(mm_14, [1, 0]);  mm_14 = None
    permute_28 = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None
    mm_15 = torch.ops.aten.mm.default(view_35, permute_28);  view_35 = permute_28 = None
    view_36 = torch.ops.aten.view.default(mm_15, [1, 1024, 4096]);  mm_15 = None
    add_11 = torch.ops.aten.add.Tensor(view_34, view_36);  view_34 = view_36 = None
    permute_29 = torch.ops.aten.permute.default(permute_27, [1, 0]);  permute_27 = None
    mul_31 = torch.ops.aten.mul.Tensor(add_11, primals_10);  primals_10 = None
    mul_32 = torch.ops.aten.mul.Tensor(add_11, convert_element_type_15);  add_11 = convert_element_type_15 = None
    sum_7 = torch.ops.aten.sum.dim_IntList(mul_32, [0, 1], True);  mul_32 = None
    view_37 = torch.ops.aten.view.default(sum_7, [4096]);  sum_7 = None
    convert_element_type_49 = torch.ops.prims.convert_element_type.default(mul_31, torch.float32);  mul_31 = None
    mul_33 = torch.ops.aten.mul.Tensor(convert_element_type_49, convert_element_type_14)
    mul_34 = torch.ops.aten.mul.Tensor(convert_element_type_49, rsqrt_1);  convert_element_type_49 = rsqrt_1 = None
    sum_8 = torch.ops.aten.sum.dim_IntList(mul_33, [2], True);  mul_33 = None
    alias_14 = torch.ops.aten.alias.default(alias_5);  alias_5 = None
    alias_15 = torch.ops.aten.alias.default(alias_14);  alias_14 = None
    pow_6 = torch.ops.aten.pow.Tensor_Scalar(alias_15, 3);  alias_15 = None
    mul_35 = torch.ops.aten.mul.Scalar(sum_8, -0.5);  sum_8 = None
    mul_36 = torch.ops.aten.mul.Tensor(mul_35, pow_6);  mul_35 = pow_6 = None
    expand_8 = torch.ops.aten.expand.default(mul_36, [1, 1024, 4096]);  mul_36 = None
    div_3 = torch.ops.aten.div.Scalar(expand_8, 4096);  expand_8 = None
    pow_7 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_14, 1.0);  convert_element_type_14 = None
    mul_37 = torch.ops.aten.mul.Scalar(pow_7, 2.0);  pow_7 = None
    mul_38 = torch.ops.aten.mul.Tensor(div_3, mul_37);  div_3 = mul_37 = None
    add_12 = torch.ops.aten.add.Tensor(mul_34, mul_38);  mul_34 = mul_38 = None
    convert_element_type_50 = torch.ops.prims.convert_element_type.default(add_12, torch.bfloat16);  add_12 = None
    add_13 = torch.ops.aten.add.Tensor(convert_element_type_36, convert_element_type_50);  convert_element_type_36 = convert_element_type_50 = None
    view_38 = torch.ops.aten.view.default(add_13, [1024, 4096])
    permute_30 = torch.ops.aten.permute.default(view_38, [1, 0])
    mm_16 = torch.ops.aten.mm.default(permute_30, view_15);  permute_30 = view_15 = None
    permute_31 = torch.ops.aten.permute.default(mm_16, [1, 0]);  mm_16 = None
    permute_32 = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None
    mm_17 = torch.ops.aten.mm.default(view_38, permute_32);  view_38 = permute_32 = None
    view_39 = torch.ops.aten.view.default(mm_17, [1, 1024, 4096]);  mm_17 = None
    permute_33 = torch.ops.aten.permute.default(permute_31, [1, 0]);  permute_31 = None
    view_40 = torch.ops.aten.view.default(view_39, [1, 1024, 32, 128]);  view_39 = None
    permute_34 = torch.ops.aten.permute.default(view_40, [0, 2, 1, 3]);  view_40 = None
    view_41 = torch.ops.aten.view.default(permute_34, [1, 2, 16, 1024, 128]);  permute_34 = None
    permute_35 = torch.ops.aten.permute.default(view_41, [1, 0, 2, 3, 4]);  view_41 = None
    clone_7 = torch.ops.aten.clone.default(permute_35, memory_format = torch.contiguous_format);  permute_35 = None
    empty_1 = torch.ops.aten.empty.memory_format([2, 1, 16, 1024, 128], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
    permute_36 = torch.ops.aten.permute.default(empty_1, [0, 1, 2, 3, 4]);  empty_1 = None
    all_to_all_single = torch.ops._c10d_functional.all_to_all_single.default(clone_7, [1, 1], [1, 1], '0');  clone_7 = None
    wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single);  all_to_all_single = None
    copy_1 = torch.ops.aten.copy.default(permute_36, wait_tensor);  permute_36 = wait_tensor = None
    permute_38 = torch.ops.aten.permute.default(copy_1, [1, 2, 0, 3, 4]);  copy_1 = None
    clone_8 = torch.ops.aten.clone.default(permute_38, memory_format = torch.contiguous_format);  permute_38 = None
    view_42 = torch.ops.aten.view.default(clone_8, [1, 16, 2048, 128]);  clone_8 = None
    alias_16 = torch.ops.aten.alias.default(alias_3);  alias_3 = None
    alias_17 = torch.ops.aten.alias.default(alias_16);  alias_16 = None
    _scaled_dot_product_efficient_attention_backward = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(view_42, all_to_all_qkv, all_to_all_qkv_1, all_to_all_qkv_2, expand_6, alias_17, getitem_1, getitem_2, getitem_3, 0.0, [True, True, True, False], scale = 0.08838834764831845);  view_42 = all_to_all_qkv = all_to_all_qkv_1 = all_to_all_qkv_2 = expand_6 = alias_17 = getitem_1 = getitem_2 = getitem_3 = None
    getitem_4 = _scaled_dot_product_efficient_attention_backward[0]
    getitem_5 = _scaled_dot_product_efficient_attention_backward[1]
    getitem_6 = _scaled_dot_product_efficient_attention_backward[2];  _scaled_dot_product_efficient_attention_backward = None
    view_43 = torch.ops.aten.view.default(getitem_6, [1, 16, 2, 1024, 128]);  getitem_6 = None
    permute_39 = torch.ops.aten.permute.default(view_43, [2, 0, 1, 3, 4]);  view_43 = None
    clone_9 = torch.ops.aten.clone.default(permute_39, memory_format = torch.contiguous_format);  permute_39 = None
    empty_2 = torch.ops.aten.empty.memory_format([2, 1, 16, 1024, 128], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
    permute_40 = torch.ops.aten.permute.default(empty_2, [0, 1, 2, 3, 4]);  empty_2 = None
    all_to_all_single_1 = torch.ops._c10d_functional.all_to_all_single.default(clone_9, [1, 1], [1, 1], '0');  clone_9 = None
    wait_tensor_1 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_1);  all_to_all_single_1 = None
    copy_2 = torch.ops.aten.copy.default(permute_40, wait_tensor_1);  permute_40 = wait_tensor_1 = None
    view_45 = torch.ops.aten.view.default(getitem_5, [1, 16, 2, 1024, 128]);  getitem_5 = None
    permute_42 = torch.ops.aten.permute.default(view_45, [2, 0, 1, 3, 4]);  view_45 = None
    clone_10 = torch.ops.aten.clone.default(permute_42, memory_format = torch.contiguous_format);  permute_42 = None
    empty_3 = torch.ops.aten.empty.memory_format([2, 1, 16, 1024, 128], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
    permute_43 = torch.ops.aten.permute.default(empty_3, [0, 1, 2, 3, 4]);  empty_3 = None
    all_to_all_single_2 = torch.ops._c10d_functional.all_to_all_single.default(clone_10, [1, 1], [1, 1], '0');  clone_10 = None
    wait_tensor_2 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_2);  all_to_all_single_2 = None
    copy_3 = torch.ops.aten.copy.default(permute_43, wait_tensor_2);  permute_43 = wait_tensor_2 = None
    view_47 = torch.ops.aten.view.default(getitem_4, [1, 16, 2, 1024, 128]);  getitem_4 = None
    permute_45 = torch.ops.aten.permute.default(view_47, [2, 0, 1, 3, 4]);  view_47 = None
    clone_11 = torch.ops.aten.clone.default(permute_45, memory_format = torch.contiguous_format);  permute_45 = None
    empty_4 = torch.ops.aten.empty.memory_format([2, 1, 16, 1024, 128], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
    permute_46 = torch.ops.aten.permute.default(empty_4, [0, 1, 2, 3, 4]);  empty_4 = None
    all_to_all_single_3 = torch.ops._c10d_functional.all_to_all_single.default(clone_11, [1, 1], [1, 1], '0');  clone_11 = None
    wait_tensor_3 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_3);  all_to_all_single_3 = None
    copy_4 = torch.ops.aten.copy.default(permute_46, wait_tensor_3);  permute_46 = wait_tensor_3 = None
    permute_48 = torch.ops.aten.permute.default(copy_3, [1, 0, 2, 3, 4]);  copy_3 = None
    view_49 = torch.ops.aten.view.default(permute_48, [1, 32, 1024, 128]);  permute_48 = None
    mul_39 = torch.ops.aten.mul.Tensor(view_49, unsqueeze_14)
    slice_35 = torch.ops.aten.slice.Tensor(mul_39, 3, 0, 64)
    slice_36 = torch.ops.aten.slice.Tensor(mul_39, 3, 64, 128);  mul_39 = None
    neg_3 = torch.ops.aten.neg.default(slice_35);  slice_35 = None
    full_6 = torch.ops.aten.full.default([1, 32, 1024, 128], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
    slice_scatter_6 = torch.ops.aten.slice_scatter.default(full_6, neg_3, 3, 64, 9223372036854775807);  full_6 = neg_3 = None
    full_7 = torch.ops.aten.full.default([1, 32, 1024, 128], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
    slice_scatter_7 = torch.ops.aten.slice_scatter.default(full_7, slice_36, 3, 0, 64);  full_7 = slice_36 = None
    add_14 = torch.ops.aten.add.Tensor(slice_scatter_6, slice_scatter_7);  slice_scatter_6 = slice_scatter_7 = None
    mul_40 = torch.ops.aten.mul.Tensor(view_49, unsqueeze_13);  view_49 = None
    add_15 = torch.ops.aten.add.Tensor(add_14, mul_40);  add_14 = mul_40 = None
    permute_49 = torch.ops.aten.permute.default(copy_4, [1, 0, 2, 3, 4]);  copy_4 = None
    view_50 = torch.ops.aten.view.default(permute_49, [1, 32, 1024, 128]);  permute_49 = None
    mul_41 = torch.ops.aten.mul.Tensor(view_50, unsqueeze_14);  unsqueeze_14 = None
    slice_37 = torch.ops.aten.slice.Tensor(mul_41, 3, 0, 64)
    slice_38 = torch.ops.aten.slice.Tensor(mul_41, 3, 64, 128);  mul_41 = None
    neg_4 = torch.ops.aten.neg.default(slice_37);  slice_37 = None
    full_8 = torch.ops.aten.full.default([1, 32, 1024, 128], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
    slice_scatter_8 = torch.ops.aten.slice_scatter.default(full_8, neg_4, 3, 64, 9223372036854775807);  full_8 = neg_4 = None
    full_9 = torch.ops.aten.full.default([1, 32, 1024, 128], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
    slice_scatter_9 = torch.ops.aten.slice_scatter.default(full_9, slice_38, 3, 0, 64);  full_9 = slice_38 = None
    add_16 = torch.ops.aten.add.Tensor(slice_scatter_8, slice_scatter_9);  slice_scatter_8 = slice_scatter_9 = None
    mul_42 = torch.ops.aten.mul.Tensor(view_50, unsqueeze_13);  view_50 = unsqueeze_13 = None
    add_17 = torch.ops.aten.add.Tensor(add_16, mul_42);  add_16 = mul_42 = None
    permute_51 = torch.ops.aten.permute.default(copy_2, [1, 0, 2, 3, 4]);  copy_2 = None
    view_51 = torch.ops.aten.view.default(permute_51, [1, 32, 1024, 128]);  permute_51 = None
    permute_52 = torch.ops.aten.permute.default(view_51, [0, 2, 1, 3]);  view_51 = None
    clone_12 = torch.ops.aten.clone.default(permute_52, memory_format = torch.contiguous_format);  permute_52 = None
    view_52 = torch.ops.aten.view.default(clone_12, [1, 1024, 4096]);  clone_12 = None
    view_53 = torch.ops.aten.view.default(view_52, [1024, 4096]);  view_52 = None
    permute_53 = torch.ops.aten.permute.default(view_53, [1, 0])
    mm_18 = torch.ops.aten.mm.default(permute_53, view_11);  permute_53 = view_11 = None
    permute_54 = torch.ops.aten.permute.default(mm_18, [1, 0]);  mm_18 = None
    permute_55 = torch.ops.aten.permute.default(permute_5, [1, 0]);  permute_5 = None
    mm_19 = torch.ops.aten.mm.default(view_53, permute_55);  view_53 = permute_55 = None
    view_54 = torch.ops.aten.view.default(mm_19, [1, 1024, 4096]);  mm_19 = None
    permute_56 = torch.ops.aten.permute.default(permute_54, [1, 0]);  permute_54 = None
    permute_57 = torch.ops.aten.permute.default(add_15, [0, 2, 1, 3]);  add_15 = None
    clone_13 = torch.ops.aten.clone.default(permute_57, memory_format = torch.contiguous_format);  permute_57 = None
    view_55 = torch.ops.aten.view.default(clone_13, [1, 1024, 4096]);  clone_13 = None
    view_56 = torch.ops.aten.view.default(view_55, [1024, 4096]);  view_55 = None
    permute_58 = torch.ops.aten.permute.default(view_56, [1, 0])
    mm_20 = torch.ops.aten.mm.default(permute_58, view_8);  permute_58 = view_8 = None
    permute_59 = torch.ops.aten.permute.default(mm_20, [1, 0]);  mm_20 = None
    permute_60 = torch.ops.aten.permute.default(permute_3, [1, 0]);  permute_3 = None
    mm_21 = torch.ops.aten.mm.default(view_56, permute_60);  view_56 = permute_60 = None
    view_57 = torch.ops.aten.view.default(mm_21, [1, 1024, 4096]);  mm_21 = None
    add_18 = torch.ops.aten.add.Tensor(view_54, view_57);  view_54 = view_57 = None
    permute_61 = torch.ops.aten.permute.default(permute_59, [1, 0]);  permute_59 = None
    permute_62 = torch.ops.aten.permute.default(add_17, [0, 2, 1, 3]);  add_17 = None
    clone_14 = torch.ops.aten.clone.default(permute_62, memory_format = torch.contiguous_format);  permute_62 = None
    view_58 = torch.ops.aten.view.default(clone_14, [1, 1024, 4096]);  clone_14 = None
    view_59 = torch.ops.aten.view.default(view_58, [1024, 4096]);  view_58 = None
    permute_63 = torch.ops.aten.permute.default(view_59, [1, 0])
    mm_22 = torch.ops.aten.mm.default(permute_63, view_5);  permute_63 = view_5 = None
    permute_64 = torch.ops.aten.permute.default(mm_22, [1, 0]);  mm_22 = None
    permute_65 = torch.ops.aten.permute.default(permute_1, [1, 0]);  permute_1 = None
    mm_23 = torch.ops.aten.mm.default(view_59, permute_65);  view_59 = permute_65 = None
    view_60 = torch.ops.aten.view.default(mm_23, [1, 1024, 4096]);  mm_23 = None
    add_19 = torch.ops.aten.add.Tensor(add_18, view_60);  add_18 = view_60 = None
    permute_66 = torch.ops.aten.permute.default(permute_64, [1, 0]);  permute_64 = None
    mul_43 = torch.ops.aten.mul.Tensor(add_19, primals_5);  primals_5 = None
    mul_44 = torch.ops.aten.mul.Tensor(add_19, convert_element_type_5);  add_19 = convert_element_type_5 = None
    sum_9 = torch.ops.aten.sum.dim_IntList(mul_44, [0, 1], True);  mul_44 = None
    view_61 = torch.ops.aten.view.default(sum_9, [4096]);  sum_9 = None
    convert_element_type_67 = torch.ops.prims.convert_element_type.default(mul_43, torch.float32);  mul_43 = None
    mul_45 = torch.ops.aten.mul.Tensor(convert_element_type_67, convert_element_type_4)
    mul_46 = torch.ops.aten.mul.Tensor(convert_element_type_67, rsqrt);  convert_element_type_67 = rsqrt = None
    sum_10 = torch.ops.aten.sum.dim_IntList(mul_45, [2], True);  mul_45 = None
    alias_18 = torch.ops.aten.alias.default(alias_1);  alias_1 = None
    alias_19 = torch.ops.aten.alias.default(alias_18);  alias_18 = None
    pow_8 = torch.ops.aten.pow.Tensor_Scalar(alias_19, 3);  alias_19 = None
    mul_47 = torch.ops.aten.mul.Scalar(sum_10, -0.5);  sum_10 = None
    mul_48 = torch.ops.aten.mul.Tensor(mul_47, pow_8);  mul_47 = pow_8 = None
    expand_9 = torch.ops.aten.expand.default(mul_48, [1, 1024, 4096]);  mul_48 = None
    div_4 = torch.ops.aten.div.Scalar(expand_9, 4096);  expand_9 = None
    pow_9 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_4, 1.0);  convert_element_type_4 = None
    mul_49 = torch.ops.aten.mul.Scalar(pow_9, 2.0);  pow_9 = None
    mul_50 = torch.ops.aten.mul.Tensor(div_4, mul_49);  div_4 = mul_49 = None
    add_20 = torch.ops.aten.add.Tensor(mul_46, mul_50);  mul_46 = mul_50 = None
    convert_element_type_68 = torch.ops.prims.convert_element_type.default(add_20, torch.bfloat16);  add_20 = None
    add_21 = torch.ops.aten.add.Tensor(add_13, convert_element_type_68);  add_13 = convert_element_type_68 = None
    convert_element_type_69 = torch.ops.prims.convert_element_type.default(add_21, torch.float32);  add_21 = None
    eq_2 = torch.ops.aten.eq.Scalar(primals_1, -1)
    unsqueeze_17 = torch.ops.aten.unsqueeze.default(eq_2, -1);  eq_2 = None
    scalar_tensor_6 = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
    where_6 = torch.ops.aten.where.self(unsqueeze_17, scalar_tensor_6, convert_element_type_69);  unsqueeze_17 = scalar_tensor_6 = convert_element_type_69 = None
    full_10 = torch.ops.aten.full.default([32000, 4096], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
    index_put = torch.ops.aten.index_put.default(full_10, [primals_1], where_6, True);  full_10 = primals_1 = where_6 = None
    convert_element_type_70 = torch.ops.prims.convert_element_type.default(index_put, torch.bfloat16);  index_put = None
    return pytree.tree_unflatten([div, view_24, None, convert_element_type_70, None, None, view_61, permute_66, permute_61, permute_56, permute_33, view_37, permute_29, permute_24, permute_20, view_30, permute_16, None], self._out_spec)
    
    primals_1: FakeTensor(..., device='cuda:0', size=(1, 1024), dtype=torch.int64)
primals_2: FakeTensor(..., device='cuda:0', size=(32000, 4096), dtype=torch.bfloat16)
primals_3: FakeTensor(..., device='cuda:0', size=(1, 2048), dtype=torch.int64)
primals_4: FakeTensor(..., device='cuda:0', size=(64,), dtype=torch.bfloat16)
primals_5: FakeTensor(..., device='cuda:0', size=(4096,), dtype=torch.bfloat16)
primals_6: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
primals_7: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
primals_8: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
primals_9: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
primals_10: FakeTensor(..., device='cuda:0', size=(4096,), dtype=torch.bfloat16)
primals_11: FakeTensor(..., device='cuda:0', size=(11008, 4096), dtype=torch.bfloat16)
primals_12: FakeTensor(..., device='cuda:0', size=(11008, 4096), dtype=torch.bfloat16)
primals_13: FakeTensor(..., device='cuda:0', size=(4096, 11008), dtype=torch.bfloat16)
primals_14: FakeTensor(..., device='cuda:0', size=(4096,), dtype=torch.bfloat16)
primals_15: FakeTensor(..., device='cuda:0', size=(32000, 4096), dtype=torch.bfloat16)
primals_16: FakeTensor(..., device='cuda:0', size=(1, 1024), dtype=torch.int64)
tangents_1: FakeTensor(..., device='cuda:0', size=())
tangents_2: FakeTensor(..., device='cuda:0', size=(1, 1024, 32000), dtype=torch.bfloat16)
embedding: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
iota: FakeTensor(..., device='cuda:0', size=(1024,), dtype=torch.int64)
unsqueeze: FakeTensor(..., device='cuda:0', size=(1, 1024), dtype=torch.int64)
full: FakeTensor(..., device='cuda:0', size=(2048, 2048), dtype=torch.bfloat16)
iota_1: FakeTensor(..., device='cuda:0', size=(2048,), dtype=torch.int64)
unsqueeze_1: FakeTensor(..., device='cuda:0', size=(1, 2048), dtype=torch.int64)
iota_2: FakeTensor(..., device='cuda:0', size=(2048,), dtype=torch.int64)
unsqueeze_2: FakeTensor(..., device='cuda:0', size=(2048, 1), dtype=torch.int64)
sub: FakeTensor(..., device='cuda:0', size=(2048, 2048), dtype=torch.int64)
ge: FakeTensor(..., device='cuda:0', size=(2048, 2048), dtype=torch.bool)
scalar_tensor: FakeTensor(..., device='cuda:0', size=(), dtype=torch.bfloat16)
where: FakeTensor(..., device='cuda:0', size=(2048, 2048), dtype=torch.bfloat16)
iota_3: FakeTensor(..., device='cuda:0', size=(2048,), dtype=torch.int64)
iota_4: FakeTensor(..., device='cuda:0', size=(2048,), dtype=torch.int64)
view: FakeTensor(..., device='cuda:0', size=(2048, 1), dtype=torch.int64)
gt: FakeTensor(..., device='cuda:0', size=(2048, 2048), dtype=torch.bool)
mul: FakeTensor(..., device='cuda:0', size=(2048, 2048), dtype=torch.bfloat16)
unsqueeze_5: FakeTensor(..., device='cuda:0', size=(1, 2048, 2048), dtype=torch.bfloat16)
unsqueeze_6: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
slice_3: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
slice_4: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
expand_1: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
clone: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
slice_5: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
slice_6: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
slice_7: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
slice_8: FakeTensor(..., device='cuda:0', size=(1, 2048), dtype=torch.int64)
unsqueeze_7: FakeTensor(..., device='cuda:0', size=(1, 1, 2048), dtype=torch.int64)
unsqueeze_8: FakeTensor(..., device='cuda:0', size=(1, 1, 1, 2048), dtype=torch.int64)
slice_9: FakeTensor(..., device='cuda:0', size=(1, 1, 1, 2048), dtype=torch.int64)
add: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
eq: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bool)
slice_10: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
slice_11: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
slice_12: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
scalar_tensor_1: FakeTensor(..., device='cuda:0', size=(), dtype=torch.bfloat16)
where_1: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
slice_13: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
slice_14: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
slice_15: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
copy: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
slice_16: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
slice_17: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
slice_scatter: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
slice_scatter_1: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
slice_scatter_2: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
eq_1: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bool)
logical_not: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bool)
any_1: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 1), dtype=torch.bool)
logical_not_1: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 1), dtype=torch.bool)
bitwise_not: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 1), dtype=torch.bool)
mul_1: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
unsqueeze_9: FakeTensor(..., device='cuda:0', size=(1, 64), dtype=torch.bfloat16)
slice_21: FakeTensor(..., device='cuda:0', size=(1, 64), dtype=torch.bfloat16)
unsqueeze_10: FakeTensor(..., device='cuda:0', size=(1, 64, 1), dtype=torch.bfloat16)
convert_element_type: FakeTensor(..., device='cuda:0', size=(1, 64, 1))
expand_2: FakeTensor(..., device='cuda:0', size=(1, 64, 1))
slice_22: FakeTensor(..., device='cuda:0', size=(1, 1024), dtype=torch.int64)
unsqueeze_11: FakeTensor(..., device='cuda:0', size=(1, 1, 1024), dtype=torch.int64)
slice_23: FakeTensor(..., device='cuda:0', size=(1, 1, 1024), dtype=torch.int64)
convert_element_type_1: FakeTensor(..., device='cuda:0', size=(1, 1, 1024))
expand_3: FakeTensor(..., device='cuda:0', size=(1, 64, 1))
view_1: FakeTensor(..., device='cuda:0', size=(1, 64, 1))
expand_4: FakeTensor(..., device='cuda:0', size=(1, 1, 1024))
view_2: FakeTensor(..., device='cuda:0', size=(1, 1, 1024))
bmm: FakeTensor(..., device='cuda:0', size=(1, 64, 1024))
view_3: FakeTensor(..., device='cuda:0', size=(1, 64, 1024))
permute: FakeTensor(..., device='cuda:0', size=(1, 1024, 64))
unsqueeze_12: FakeTensor(..., device='cuda:0', size=(1, 1024, 1, 64))
expand_5: FakeTensor(..., device='cuda:0', size=(1, 1024, 2, 64))
clone_1: FakeTensor(..., device='cuda:0', size=(1, 1024, 2, 64))
view_4: FakeTensor(..., device='cuda:0', size=(1, 1024, 128))
clone_2: FakeTensor(..., device='cuda:0', size=(1, 1024, 128))
cos: FakeTensor(..., device='cuda:0', size=(1, 1024, 128))
sin: FakeTensor(..., device='cuda:0', size=(1, 1024, 128))
mul_2: FakeTensor(..., device='cuda:0', size=(1, 1024, 128))
mul_3: FakeTensor(..., device='cuda:0', size=(1, 1024, 128))
convert_element_type_2: FakeTensor(..., device='cuda:0', size=(1, 1024, 128), dtype=torch.bfloat16)
convert_element_type_3: FakeTensor(..., device='cuda:0', size=(1, 1024, 128), dtype=torch.bfloat16)
convert_element_type_4: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
pow_1: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
mean: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
add_1: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
rsqrt: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
alias: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
alias_1: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
mul_4: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
convert_element_type_5: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
mul_5: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
permute_1: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
view_5: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
mm: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
view_6: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
view_7: FakeTensor(..., device='cuda:0', size=(1, 1024, 32, 128), dtype=torch.bfloat16)
permute_2: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
permute_3: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
view_8: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
mm_1: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
view_9: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
view_10: FakeTensor(..., device='cuda:0', size=(1, 1024, 32, 128), dtype=torch.bfloat16)
permute_4: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
permute_5: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
view_11: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
mm_2: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
view_12: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
view_13: FakeTensor(..., device='cuda:0', size=(1, 1024, 32, 128), dtype=torch.bfloat16)
permute_6: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
unsqueeze_13: FakeTensor(..., device='cuda:0', size=(1, 1, 1024, 128), dtype=torch.bfloat16)
unsqueeze_14: FakeTensor(..., device='cuda:0', size=(1, 1, 1024, 128), dtype=torch.bfloat16)
mul_6: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
slice_24: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 64), dtype=torch.bfloat16)
slice_25: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 64), dtype=torch.bfloat16)
neg: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 64), dtype=torch.bfloat16)
cat: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
mul_7: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
add_2: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
mul_8: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
slice_26: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 64), dtype=torch.bfloat16)
slice_27: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 64), dtype=torch.bfloat16)
neg_1: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 64), dtype=torch.bfloat16)
cat_1: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
mul_9: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
add_3: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
slice_28: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
slice_29: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
slice_30: FakeTensor(..., device='cuda:0', size=(1, 1, 2048, 2048), dtype=torch.bfloat16)
clone_3: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
all_to_all_qkv: FakeTensor(..., device='cuda:0', size=(1, 16, 2048, 128), dtype=torch.bfloat16)
clone_4: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
all_to_all_qkv_1: FakeTensor(..., device='cuda:0', size=(1, 16, 2048, 128), dtype=torch.bfloat16)
clone_5: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
all_to_all_qkv_2: FakeTensor(..., device='cuda:0', size=(1, 16, 2048, 128), dtype=torch.bfloat16)
expand_6: FakeTensor(..., device='cuda:0', size=(1, 16, 2048, 2048),
           dtype=torch.bfloat16)
_scaled_dot_product_efficient_attention: (FakeTensor(..., device='cuda:0', size=(1, 16, 2048, 128), dtype=torch.bfloat16), FakeTensor(..., device='cuda:0', size=(1, 16, 2048)), FakeTensor(..., device='cuda:0', size=(), dtype=torch.int64), FakeTensor(..., device='cuda:0', size=(), dtype=torch.int64))
getitem: FakeTensor(..., device='cuda:0', size=(1, 16, 2048, 128), dtype=torch.bfloat16)
getitem_1: FakeTensor(..., device='cuda:0', size=(1, 16, 2048))
getitem_2: FakeTensor(..., device='cuda:0', size=(), dtype=torch.int64)
getitem_3: FakeTensor(..., device='cuda:0', size=(), dtype=torch.int64)
alias_2: FakeTensor(..., device='cuda:0', size=(1, 16, 2048, 128), dtype=torch.bfloat16)
alias_3: FakeTensor(..., device='cuda:0', size=(1, 16, 2048, 128), dtype=torch.bfloat16)
all_to_all_out: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
permute_7: FakeTensor(..., device='cuda:0', size=(1, 1024, 32, 128), dtype=torch.bfloat16)
clone_6: FakeTensor(..., device='cuda:0', size=(1, 1024, 32, 128), dtype=torch.bfloat16)
view_14: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
permute_8: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
view_15: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
mm_3: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
view_16: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
add_4: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
convert_element_type_14: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
pow_2: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
mean_1: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
add_5: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
rsqrt_1: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
alias_4: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
alias_5: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
mul_10: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
convert_element_type_15: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
mul_11: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
permute_9: FakeTensor(..., device='cuda:0', size=(4096, 11008), dtype=torch.bfloat16)
view_17: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
mm_4: FakeTensor(..., device='cuda:0', size=(1024, 11008), dtype=torch.bfloat16)
view_18: FakeTensor(..., device='cuda:0', size=(1, 1024, 11008), dtype=torch.bfloat16)
convert_element_type_18: FakeTensor(..., device='cuda:0', size=(1, 1024, 11008))
sigmoid: FakeTensor(..., device='cuda:0', size=(1, 1024, 11008))
mul_12: FakeTensor(..., device='cuda:0', size=(1, 1024, 11008))
convert_element_type_19: FakeTensor(..., device='cuda:0', size=(1, 1024, 11008), dtype=torch.bfloat16)
permute_10: FakeTensor(..., device='cuda:0', size=(4096, 11008), dtype=torch.bfloat16)
view_19: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
mm_5: FakeTensor(..., device='cuda:0', size=(1024, 11008), dtype=torch.bfloat16)
view_20: FakeTensor(..., device='cuda:0', size=(1, 1024, 11008), dtype=torch.bfloat16)
mul_13: FakeTensor(..., device='cuda:0', size=(1, 1024, 11008), dtype=torch.bfloat16)
permute_11: FakeTensor(..., device='cuda:0', size=(11008, 4096), dtype=torch.bfloat16)
view_21: FakeTensor(..., device='cuda:0', size=(1024, 11008), dtype=torch.bfloat16)
mm_6: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
view_22: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
add_6: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
convert_element_type_24: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
pow_3: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
mean_2: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
add_7: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
rsqrt_2: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
alias_6: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
alias_7: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
mul_14: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
convert_element_type_25: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
mul_15: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
slice_31: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
slice_32: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
slice_33: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
permute_12: FakeTensor(..., device='cuda:0', size=(4096, 32000), dtype=torch.bfloat16)
view_23: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
mm_7: FakeTensor(..., device='cuda:0', size=(1024, 32000), dtype=torch.bfloat16)
view_24: FakeTensor(..., device='cuda:0', size=(1, 1024, 32000), dtype=torch.bfloat16)
convert_element_type_28: FakeTensor(..., device='cuda:0', size=(1, 1024, 32000))
constant_pad_nd: FakeTensor(..., device='cuda:0', size=(1, 1025), dtype=torch.int64)
slice_34: FakeTensor(..., device='cuda:0', size=(1, 1024), dtype=torch.int64)
view_25: FakeTensor(..., device='cuda:0', size=(1024, 32000))
view_26: FakeTensor(..., device='cuda:0', size=(1024,), dtype=torch.int64)
amax: FakeTensor(..., device='cuda:0', size=(1024, 1))
sub_1: FakeTensor(..., device='cuda:0', size=(1024, 32000))
exp: FakeTensor(..., device='cuda:0', size=(1024, 32000))
sum_1: FakeTensor(..., device='cuda:0', size=(1024, 1))
log: FakeTensor(..., device='cuda:0', size=(1024, 1))
sub_2: FakeTensor(..., device='cuda:0', size=(1024, 32000))
alias_8: FakeTensor(..., device='cuda:0', size=(1024, 32000))
alias_9: FakeTensor(..., device='cuda:0', size=(1024, 32000))
ne: FakeTensor(..., device='cuda:0', size=(1024,), dtype=torch.bool)
scalar_tensor_2: FakeTensor(..., device='cuda:0', size=(), dtype=torch.int64)
where_2: FakeTensor(..., device='cuda:0', size=(1024,), dtype=torch.int64)
unsqueeze_15: FakeTensor(..., device='cuda:0', size=(1024, 1), dtype=torch.int64)
gather: FakeTensor(..., device='cuda:0', size=(1024, 1))
squeeze: FakeTensor(..., device='cuda:0', size=(1024,))
neg_2: FakeTensor(..., device='cuda:0', size=(1024,))
ne_1: FakeTensor(..., device='cuda:0', size=(1024,), dtype=torch.bool)
scalar_tensor_3: FakeTensor(..., device='cuda:0', size=())
where_3: FakeTensor(..., device='cuda:0', size=(1024,))
ne_2: FakeTensor(..., device='cuda:0', size=(1024,), dtype=torch.bool)
sum_2: FakeTensor(..., device='cuda:0', size=(), dtype=torch.int64)
convert_element_type_29: FakeTensor(..., device='cuda:0', size=())
sum_3: FakeTensor(..., device='cuda:0', size=())
div: FakeTensor(..., device='cuda:0', size=())
div_1: FakeTensor(..., device='cuda:0', size=())
unsqueeze_16: FakeTensor(..., device='cuda:0', size=(1024, 1), dtype=torch.int64)
ne_3: FakeTensor(..., device='cuda:0', size=(1024, 1), dtype=torch.bool)
scalar_tensor_4: FakeTensor(..., device='cuda:0', size=(), dtype=torch.int64)
where_4: FakeTensor(..., device='cuda:0', size=(1024, 1), dtype=torch.int64)
full_1: FakeTensor(..., device='cuda:0', size=(1024, 32000))
scatter: FakeTensor(..., device='cuda:0', size=(1024, 32000))
ne_4: FakeTensor(..., device='cuda:0', size=(1024, 1), dtype=torch.bool)
scalar_tensor_5: FakeTensor(..., device='cuda:0', size=())
where_5: FakeTensor(..., device='cuda:0', size=(1024, 1))
mul_16: FakeTensor(..., device='cuda:0', size=(1024, 32000))
alias_10: FakeTensor(..., device='cuda:0', size=(1024, 32000))
alias_11: FakeTensor(..., device='cuda:0', size=(1024, 32000))
exp_1: FakeTensor(..., device='cuda:0', size=(1024, 32000))
sum_4: FakeTensor(..., device='cuda:0', size=(1024, 1))
mul_17: FakeTensor(..., device='cuda:0', size=(1024, 32000))
sub_3: FakeTensor(..., device='cuda:0', size=(1024, 32000))
view_27: FakeTensor(..., device='cuda:0', size=(1, 1024, 32000))
convert_element_type_30: FakeTensor(..., device='cuda:0', size=(1, 1024, 32000), dtype=torch.bfloat16)
add_8: FakeTensor(..., device='cuda:0', size=(1, 1024, 32000), dtype=torch.bfloat16)
view_28: FakeTensor(..., device='cuda:0', size=(1024, 32000), dtype=torch.bfloat16)
permute_13: FakeTensor(..., device='cuda:0', size=(32000, 1024), dtype=torch.bfloat16)
mm_8: FakeTensor(..., device='cuda:0', size=(32000, 4096), dtype=torch.bfloat16)
permute_14: FakeTensor(..., device='cuda:0', size=(4096, 32000), dtype=torch.bfloat16)
permute_15: FakeTensor(..., device='cuda:0', size=(32000, 4096), dtype=torch.bfloat16)
mm_9: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
view_29: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
permute_16: FakeTensor(..., device='cuda:0', size=(32000, 4096), dtype=torch.bfloat16)
full_2: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
slice_scatter_3: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
full_3: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
slice_scatter_4: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
full_4: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
slice_scatter_5: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
mul_18: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
mul_19: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
sum_5: FakeTensor(..., device='cuda:0', size=(1, 1, 4096), dtype=torch.bfloat16)
view_30: FakeTensor(..., device='cuda:0', size=(4096,), dtype=torch.bfloat16)
convert_element_type_35: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
mul_20: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
mul_21: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
sum_6: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
alias_12: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
alias_13: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
pow_4: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
mul_22: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
mul_23: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
expand_7: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
div_2: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
pow_5: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
mul_24: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
mul_25: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
add_9: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
convert_element_type_36: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
view_31: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
permute_17: FakeTensor(..., device='cuda:0', size=(4096, 1024), dtype=torch.bfloat16)
mm_10: FakeTensor(..., device='cuda:0', size=(4096, 11008), dtype=torch.bfloat16)
permute_18: FakeTensor(..., device='cuda:0', size=(11008, 4096), dtype=torch.bfloat16)
permute_19: FakeTensor(..., device='cuda:0', size=(4096, 11008), dtype=torch.bfloat16)
mm_11: FakeTensor(..., device='cuda:0', size=(1024, 11008), dtype=torch.bfloat16)
view_32: FakeTensor(..., device='cuda:0', size=(1, 1024, 11008), dtype=torch.bfloat16)
permute_20: FakeTensor(..., device='cuda:0', size=(4096, 11008), dtype=torch.bfloat16)
mul_26: FakeTensor(..., device='cuda:0', size=(1, 1024, 11008), dtype=torch.bfloat16)
mul_27: FakeTensor(..., device='cuda:0', size=(1, 1024, 11008), dtype=torch.bfloat16)
view_33: FakeTensor(..., device='cuda:0', size=(1024, 11008), dtype=torch.bfloat16)
permute_21: FakeTensor(..., device='cuda:0', size=(11008, 1024), dtype=torch.bfloat16)
mm_12: FakeTensor(..., device='cuda:0', size=(11008, 4096), dtype=torch.bfloat16)
permute_22: FakeTensor(..., device='cuda:0', size=(4096, 11008), dtype=torch.bfloat16)
permute_23: FakeTensor(..., device='cuda:0', size=(11008, 4096), dtype=torch.bfloat16)
mm_13: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
view_34: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
permute_24: FakeTensor(..., device='cuda:0', size=(11008, 4096), dtype=torch.bfloat16)
sigmoid_1: FakeTensor(..., device='cuda:0', size=(1, 1024, 11008), dtype=torch.bfloat16)
full_5: FakeTensor(..., device='cuda:0', size=(1, 1024, 11008), dtype=torch.bfloat16)
sub_4: FakeTensor(..., device='cuda:0', size=(1, 1024, 11008), dtype=torch.bfloat16)
mul_28: FakeTensor(..., device='cuda:0', size=(1, 1024, 11008), dtype=torch.bfloat16)
add_10: FakeTensor(..., device='cuda:0', size=(1, 1024, 11008), dtype=torch.bfloat16)
mul_29: FakeTensor(..., device='cuda:0', size=(1, 1024, 11008), dtype=torch.bfloat16)
mul_30: FakeTensor(..., device='cuda:0', size=(1, 1024, 11008), dtype=torch.bfloat16)
view_35: FakeTensor(..., device='cuda:0', size=(1024, 11008), dtype=torch.bfloat16)
permute_26: FakeTensor(..., device='cuda:0', size=(11008, 1024), dtype=torch.bfloat16)
mm_14: FakeTensor(..., device='cuda:0', size=(11008, 4096), dtype=torch.bfloat16)
permute_27: FakeTensor(..., device='cuda:0', size=(4096, 11008), dtype=torch.bfloat16)
permute_28: FakeTensor(..., device='cuda:0', size=(11008, 4096), dtype=torch.bfloat16)
mm_15: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
view_36: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
add_11: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
permute_29: FakeTensor(..., device='cuda:0', size=(11008, 4096), dtype=torch.bfloat16)
mul_31: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
mul_32: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
sum_7: FakeTensor(..., device='cuda:0', size=(1, 1, 4096), dtype=torch.bfloat16)
view_37: FakeTensor(..., device='cuda:0', size=(4096,), dtype=torch.bfloat16)
convert_element_type_49: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
mul_33: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
mul_34: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
sum_8: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
alias_14: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
alias_15: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
pow_6: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
mul_35: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
mul_36: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
expand_8: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
div_3: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
pow_7: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
mul_37: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
mul_38: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
add_12: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
convert_element_type_50: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
add_13: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
view_38: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
permute_30: FakeTensor(..., device='cuda:0', size=(4096, 1024), dtype=torch.bfloat16)
mm_16: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
permute_31: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
permute_32: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
mm_17: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
view_39: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
permute_33: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
view_40: FakeTensor(..., device='cuda:0', size=(1, 1024, 32, 128), dtype=torch.bfloat16)
permute_34: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
view_41: FakeTensor(..., device='cuda:0', size=(1, 2, 16, 1024, 128),
           dtype=torch.bfloat16)
permute_35: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
clone_7: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
empty_1: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
permute_36: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
all_to_all_single: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
wait_tensor: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
copy_1: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
permute_38: FakeTensor(..., device='cuda:0', size=(1, 16, 2, 1024, 128),
           dtype=torch.bfloat16)
clone_8: FakeTensor(..., device='cuda:0', size=(1, 16, 2, 1024, 128),
           dtype=torch.bfloat16)
view_42: FakeTensor(..., device='cuda:0', size=(1, 16, 2048, 128), dtype=torch.bfloat16)
alias_16: FakeTensor(..., device='cuda:0', size=(1, 16, 2048, 128), dtype=torch.bfloat16)
alias_17: FakeTensor(..., device='cuda:0', size=(1, 16, 2048, 128), dtype=torch.bfloat16)
_scaled_dot_product_efficient_attention_backward: (FakeTensor(..., device='cuda:0', size=(1, 16, 2048, 128), dtype=torch.bfloat16), FakeTensor(..., device='cuda:0', size=(1, 16, 2048, 128), dtype=torch.bfloat16), FakeTensor(..., device='cuda:0', size=(1, 16, 2048, 128), dtype=torch.bfloat16), None)
getitem_4: FakeTensor(..., device='cuda:0', size=(1, 16, 2048, 128), dtype=torch.bfloat16)
getitem_5: FakeTensor(..., device='cuda:0', size=(1, 16, 2048, 128), dtype=torch.bfloat16)
getitem_6: FakeTensor(..., device='cuda:0', size=(1, 16, 2048, 128), dtype=torch.bfloat16)
view_43: FakeTensor(..., device='cuda:0', size=(1, 16, 2, 1024, 128),
           dtype=torch.bfloat16)
permute_39: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
clone_9: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
empty_2: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
permute_40: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
all_to_all_single_1: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
wait_tensor_1: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
copy_2: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
view_45: FakeTensor(..., device='cuda:0', size=(1, 16, 2, 1024, 128),
           dtype=torch.bfloat16)
permute_42: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
clone_10: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
empty_3: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
permute_43: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
all_to_all_single_2: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
wait_tensor_2: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
copy_3: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
view_47: FakeTensor(..., device='cuda:0', size=(1, 16, 2, 1024, 128),
           dtype=torch.bfloat16)
permute_45: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
clone_11: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
empty_4: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
permute_46: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
all_to_all_single_3: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
wait_tensor_3: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
copy_4: FakeTensor(..., device='cuda:0', size=(2, 1, 16, 1024, 128),
           dtype=torch.bfloat16)
permute_48: FakeTensor(..., device='cuda:0', size=(1, 2, 16, 1024, 128),
           dtype=torch.bfloat16)
view_49: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
mul_39: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
slice_35: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 64), dtype=torch.bfloat16)
slice_36: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 64), dtype=torch.bfloat16)
neg_3: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 64), dtype=torch.bfloat16)
full_6: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
slice_scatter_6: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
full_7: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
slice_scatter_7: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
add_14: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
mul_40: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
add_15: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
permute_49: FakeTensor(..., device='cuda:0', size=(1, 2, 16, 1024, 128),
           dtype=torch.bfloat16)
view_50: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
mul_41: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
slice_37: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 64), dtype=torch.bfloat16)
slice_38: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 64), dtype=torch.bfloat16)
neg_4: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 64), dtype=torch.bfloat16)
full_8: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
slice_scatter_8: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
full_9: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
slice_scatter_9: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
add_16: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
mul_42: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
add_17: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
permute_51: FakeTensor(..., device='cuda:0', size=(1, 2, 16, 1024, 128),
           dtype=torch.bfloat16)
view_51: FakeTensor(..., device='cuda:0', size=(1, 32, 1024, 128), dtype=torch.bfloat16)
permute_52: FakeTensor(..., device='cuda:0', size=(1, 1024, 32, 128), dtype=torch.bfloat16)
clone_12: FakeTensor(..., device='cuda:0', size=(1, 1024, 32, 128), dtype=torch.bfloat16)
view_52: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
view_53: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
permute_53: FakeTensor(..., device='cuda:0', size=(4096, 1024), dtype=torch.bfloat16)
mm_18: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
permute_54: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
permute_55: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
mm_19: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
view_54: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
permute_56: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
permute_57: FakeTensor(..., device='cuda:0', size=(1, 1024, 32, 128), dtype=torch.bfloat16)
clone_13: FakeTensor(..., device='cuda:0', size=(1, 1024, 32, 128), dtype=torch.bfloat16)
view_55: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
view_56: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
permute_58: FakeTensor(..., device='cuda:0', size=(4096, 1024), dtype=torch.bfloat16)
mm_20: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
permute_59: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
permute_60: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
mm_21: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
view_57: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
add_18: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
permute_61: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
permute_62: FakeTensor(..., device='cuda:0', size=(1, 1024, 32, 128), dtype=torch.bfloat16)
clone_14: FakeTensor(..., device='cuda:0', size=(1, 1024, 32, 128), dtype=torch.bfloat16)
view_58: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
view_59: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
permute_63: FakeTensor(..., device='cuda:0', size=(4096, 1024), dtype=torch.bfloat16)
mm_22: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
permute_64: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
permute_65: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
mm_23: FakeTensor(..., device='cuda:0', size=(1024, 4096), dtype=torch.bfloat16)
view_60: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
add_19: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
permute_66: FakeTensor(..., device='cuda:0', size=(4096, 4096), dtype=torch.bfloat16)
mul_43: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
mul_44: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
sum_9: FakeTensor(..., device='cuda:0', size=(1, 1, 4096), dtype=torch.bfloat16)
view_61: FakeTensor(..., device='cuda:0', size=(4096,), dtype=torch.bfloat16)
convert_element_type_67: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
mul_45: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
mul_46: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
sum_10: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
alias_18: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
alias_19: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
pow_8: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
mul_47: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
mul_48: FakeTensor(..., device='cuda:0', size=(1, 1024, 1))
expand_9: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
div_4: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
pow_9: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
mul_49: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
mul_50: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
add_20: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
convert_element_type_68: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
add_21: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096), dtype=torch.bfloat16)
convert_element_type_69: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
eq_2: FakeTensor(..., device='cuda:0', size=(1, 1024), dtype=torch.bool)
unsqueeze_17: FakeTensor(..., device='cuda:0', size=(1, 1024, 1), dtype=torch.bool)
scalar_tensor_6: FakeTensor(..., device='cuda:0', size=())
where_6: FakeTensor(..., device='cuda:0', size=(1, 1024, 4096))
full_10: FakeTensor(..., device='cuda:0', size=(32000, 4096))
index_put: FakeTensor(..., device='cuda:0', size=(32000, 4096))
convert_element_type_70: FakeTensor(..., device='cuda:0', size=(32000, 4096), dtype=torch.bfloat16)